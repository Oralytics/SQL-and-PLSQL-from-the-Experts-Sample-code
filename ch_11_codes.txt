—-
—- Real World SQL and PL/SQL from the Experts
—-    Published by : McGraw-Hill / Oracle Press
—-
—- Chapter 11 - Oracle R Enterprise
—-

full_dataset <- CUSTOMER_V AggData <- aggregate(full_dataset$CUST_ID,        by = list(CUST_GENDER = full_dataset$CUST_GENDER),        FUN = length) AggData   # To view some of the ORE Transparency Layer metadata
AggData@dataQry   


## Install the Oracle R Enterprise Client Packages ## ## Need to ensure your Client has the correct version of R or Oracle R Distribution ## install.packages("C:/app/ORE_Client_Install/client/ORE_1.5.zip") install.packages("C:/app/ORE_Client_Install/client/OREbase_1.5.zip") install.packages("C:/app/ORE_Client_Install/client/OREcommon_1.5.zip") install.packages("C:/app/ORE_Client_Install/client/OREdm_1.5.zip") install.packages("C:/app/ORE_Client_Install/client/OREeda_1.5.zip") install.packages("C:/app/ORE_Client_Install/client/OREembed_1.5.zip") install.packages("C:/app/ORE_Client_Install/client/OREgraphics_1.5.zip") install.packages("C:/app/ORE_Client_Install/client/OREmodels_1.5.zip") install.packages("C:/app/ORE_Client_Install/client/OREpredict_1.5.zip") install.packages("C:/app/ORE_Client_Install/client/OREstats_1.5.zip") install.packages("C:/app/ORE_Clien_Install/client/ORExml_1.5.zip")    ## Install the ORE Supporting packages  install.packages("C:/app/ORE_Client_Install/supporting/arules_1.1-9.zip") install.packages("C:/app/ORE_Client_Install/supporting/Cairo_1.5-8.zip") install.packages("C:/app/ORE_Client_Install/supporting/DBI_0.3.1.zip") install.packages("C:/app/ORE_Client_Install/supporting/png_0.1-7.zip") install.packages("C:/app/ORE_Client_Install/supporting/randomForest_4.6-10.zip") install.packages("C:/app/ORE_Client_Install/supporting/ROracle_1.2-1.zip") install.packages("C:/app/ORE_Client_Install/supporting/statmod_1.4.21.zip")# First you need to load the ORE libarylibrary(ORE) # Create an ORE connection to your Oracle Schemaore.connect(user="ore_user", password="ore_user", host="localhost", service_name="PDB12C", port=1521, all=TRUE) 

# Test that we are connectedore.is.connected() # List the objects that are in the Oracle Schema  -- No objects exist if a new schemaore.ls() ore.doEval(function() .libPaths() )

#  Setup Demo data
ore.exec("DROP VIEW customers_v") ore.exec("DROP VIEW products_v") ore.exec("DROP VIEW countries_v") ore.exec("DROP VIEW sales_v") # You will need select privileges on the tables in the SH schemaore.exec("CREATE VIEW customers_v AS SELECT * FROM sh.customers") ore.exec("CREATE VIEW products_v AS SELECT * FROM sh.products") ore.exec("CREATE VIEW countries_v AS SELECT * FROM sh.countries") ore.exec("CREATE VIEW sales_v AS SELECT * FROM sh.sales") # create a view for Customers who live in USA ore.exec("CREATE TABLE customers_usa             AS SELECT * FROM customers_v WHERE COUNTRY_ID = 52790") # put the new Customers table in memory ore.exec("ALTER TABLE customers_usa inmemory") ore.sync() ore.ls() # create a local variable ds that points to SALES_V in the databaseds <- ore.get("SALES_V")# list the attributes of the SALES_V. This is the same as using DESC in SQLnames(ds) # We can verify we are pointing at the object in the databaseclass(ds) # How many rows and columns are in the tabledim(ds) # Display the first 6 records from the tablehead(ds)# Get the Summary statistics for each attribute in SALES_Vsummary(ds)  # Create a local copy of the SALES_V datasales_ds <- ore.pull(SALES_V) # Check to see that this is a local data frame and not an ORE objectclass(sales_ds) # Get details of the local datadim(sales_ds) # Push the mtcars data set to the Oracle Database
cars_ore_ds<-ore.push(mtcars) 

# Create a table in the Oracle Schema for the mtcars data
ore.create(mtcars, "CARS_DATA")

# Drop a table
ore.drop("CARS_DATA")

# Disconnect your ORE session from the Oracle Database
ore.disconnect()

# EDA - Examples # # Use the CUSTOMERS_V data. It is in our schema in the Database full_dataset <- V # list the attributes of the CUSTOMERS_USA table in the database.names(full_dataset) # Generate the summary statistics ore.summary(full_dataset, var="CUST_YEAR_OF_BIRTH")ore.summary(full_dataset, var="CUST_YEAR_OF_BIRTH",               stats=c("n", "nmiss", "min", "max", "var", "range") )    ore.summary(full_dataset, class="CUST_GENDER", var="CUST_YEAR_OF_BIRTH")

ore.summary(full_dataset, class=c("CUST_CITY", "CUST_GENDER"),               var="CUST_YEAR_OF_BIRTH", ways=2)# Use the CUSTOMERS_V data. It is in our schema in the Database full_dataset <- CUSTOMERS_V # add an index to the data frame row.names(full_dataset) <- full_dataset$CUST_ID # Remap the following to numeric data type full_dataset$CUST_POSTAL_CODE <- as.numeric(full_dataset$CUST_POSTAL_CODE) full_dataset$CUST_CITY_ID <- as.numeric(full_dataset$CUST_CITY_ID) 
# Correlation analysis using Pearson ore.corr(full_dataset, var="CUST_POSTAL_CODE, CUST_CITY_ID")# Correlation analysis using Spearmanore.corr(full_dataset, var="CUST_POSTAL_CODE, CUST_CITY_ID", stats="spearman")# Use the CUSTOMERS_V data. It is in our schema in the Database full_dataset <- CUSTOMERS_V # add an index to the data frame row.names(full_dataset) <- full_dataset$CUST_ID # Crosstab example ore.crosstab(~CUST_GENDER, data=full_dataset)
full_dataset$AGE <- as.numeric(format(Sys.time(), "%Y")) -                      full_dataset$CUST_YEAR_OF_BIRTH # Analyze Age by Customer Gender ore.crosstab(AGE~CUST_GENDER, data=full_dataset) # Create a Sorted dataset of the Ranked Data ranked_data <- ore.rank(full_dataset, var="CUST_CREDIT_LIMIT=Rank_CL",                         group.by="CUST_CITY", percent=TRUE, ties="dense") sorted_ranked_data <- ore.sort(ranked_data, by=c("CUST_CITY", "Rank_CL")) head(sorted_ranked_data,30)# Stratified Sampling example# full_dataset <- CUSTOMERS_V # add an index to the data frame row.names(full_dataset) <- full_dataset$CUST_ID # Check the class of the object. It should be an ore.frame pointing #   to the object in the Database class(full_dataset) # Set the sample size SampleSize <- 1000 # Calculate the total number of records in the full data setNRows_Dataset = nrow(full_dataset) # Create the Stratified data set based on using the CUST_GENER attribue stratified_sample <- do.call(rbind,            lapply(split(full_dataset, full_dataset$CUST_GENDER),             function(y) {                NumRows <- nrow(y)                 y[sample(NumRows, SampleSize*NumRows/NRows_Dataset), , drop=FALSE]             })) class(stratified_sample) nrow(stratified_sample) 

# Sorting Data # Sort the data set by COUNTRY_REGION (in ascending order by default) ore.sort(data = customers, by = "COUNTRY_REGION") # Sort the data by COUNTRY_REGION in descending order ore.sort(data = customers, by = "COUNTRY_REGION", reverse=TRUE) # Sort the data set by COUNTRY_REGION and AGE_BIN ore.sort(data = customers, by = c("COUNTRY_REGION","AGE_BIN")) # Sort the data by COUNTRY_REGION ascending and by CUST_YEAR_OF_BIRTH in descending order #  You will notices a different way for indicating Descending order. This is to be used #    when sorting your data using a combination of 2 or more attributes. cust_sorted <- ore.sort(data = customers, by = c("COUNTRY_REGION","-CUST_YEAR_OF_BIRTH")) # Sorted data is stored in an ORE data frame called 'cust_sorted' #   This allows you to perform additional data manipulations on the data set #  The following displays 3 of the attributes from the sorted data set head(cust_sorted[,c("AGE_BIN","COUNTRY_REGION","CUST_YEAR_OF_BIRTH")], 20)# Build an Association Rules model using ore.odmAssocRules ore.exec("CREATE OR REPLACE VIEW AR_TRANSACTIONS   AS    SELECT s.cust_id || s.time_id  case_id,          p.prod_name   FROM   sh.sales s,         sh.products p   WHERE s.prod_id = p.prod_id")  # You need to sync the meta data for the newly created view to be visable in#  your ORE sessionore.sync() ore.ls() # List the attributes of the AR_TRANSACTION viewnames(AR_TRANSACTIONS)  # Generate the Association Rules modelARmodel <- ore.odmAssocRules(~., AR_TRANSACTIONS, case.id.column = "CASE_ID",                                        item.id.column = "PROD_NAME", min.support = 0.06, min.confidence = 0.1) # List the various pieces of information that is part of the modelnames(ARmodel) # List all the information about the modelsummary(ARmodel)                                                                                                                                                                   
# Bring the Association Rules to the client & use the 'arules' package #  to see more details of the association rules #install.packages("arules") library(arules) ARrules <- rules(ARmodel) local_ARrules <- ore.pull(ARrules) inspect(local_ARrules)  ARitemsets <- itemsets(ARmodel) local_ARitemsets <- ore.pull(ARitemsets) inspect(local_ARitemsets) 

ore.exec(" CREATE OR REPLACE VIEW ANALYTIC_RECORD   AS    SELECT a.CUST_ID,   a.CUST_GENDER,   2003-a.CUST_YEAR_OF_BIRTH AGE,   a.CUST_MARITAL_STATUS,   c.COUNTRY_NAME,   a.CUST_INCOME_LEVEL,   b.EDUCATION,   b.OCCUPATION,   b.HOUSEHOLD_SIZE,   b.YRS_RESIDENCE,   b.AFFINITY_CARD,   b.BULK_PACK_DISKETTES,   b.FLAT_PANEL_MONITOR,   b.HOME_THEATER_PACKAGE,   b.BOOKKEEPING_APPLICATION,   b.PRINTER_SUPPLIES,   b.Y_BOX_GAMES,   b.OS_DOC_SET_KANJI   FROM sh.customers a,       sh.supplementary_demographics b,       sh.countries c   WHERE a.CUST_ID = b.CUST_ID    AND a.country_id  = c.country_id   AND a.cust_id between 101501 and 103000")  # You need to run the ore.sync function to bring the meta data of this #   view into your sessionore.sync() ore.ls()# Build a Decision Tree model using ore.odmDT DTmodel <- ore.odmDT(AFFINITY_CARD ~., ANALYTIC_RECORD) class(DTmodel) names(DTmodel) summary(DTmodel)


ore.exec(" CREATE OR REPLACE VIEW TEST_DATA   AS    SELECT a.CUST_ID,   a.CUST_GENDER,   2003-a.CUST_YEAR_OF_BIRTH AGE,   a.CUST_MARITAL_STATUS,   c.COUNTRY_NAME,   a.CUST_INCOME_LEVEL,   b.EDUCATION,   b.OCCUPATION,   b.HOUSEHOLD_SIZE,   b.YRS_RESIDENCE,   b.AFFINITY_CARD,   b.BULK_PACK_DISKETTES,   b.FLAT_PANEL_MONITOR,   b.HOME_THEATER_PACKAGE,   b.BOOKKEEPING_APPLICATION,   b.PRINTER_SUPPLIES,   b.Y_BOX_GAMES,   b.OS_DOC_SET_KANJI   FROM sh.customers a,       sh.supplementary_demographics b,       sh.countries c   WHERE a.CUST_ID = b.CUST_ID    AND a.country_id  = c.country_id   AND a.cust_id between 103001 and 104500") 

# Test the Decision Tree model DTtest <- predict(DTmodel, TEST_DATA, "AFFINITY_CARD") # Generate the confusion Matrix with(DTtest, table(AFFINITY_CARD, PREDICTION))# Add an index to the data set. This is needed when using the cbingDTnew <- predict(DTmodel, NEW_DATA, "AFFINITY_CARD")# Combine the New Data Set with the scored valuesDTresults <- cbind(TEST_DATA, DTnew)head(DTresults, 5)# Build a Neural Network using ore.neural Nmodel <- ore.neural(AFFINITY_CARD ~., data = ANALYTIC_RECORD) summary(Nmodel) Ntest <- predict(Nmodel, TEST_DATA, supplemental.cols=c("CUST_ID")) row.names(Ntest) <- Ntest$CUST_ID  Nresult <- cbind(TEST_DATA, Ntest ) head(Nresult, 5)

# Embedded R Execution using SQL and PL/SQL
BEGIN--    sys.rqScriptDrop('HelloWorld');    sys.rqScriptCreate('HelloWorld',       'function() {          res <- data.frame(Ans="Hello World", stringsAsFactors=FALSE)          res} ');END;/SELECT * FROM    table ( rqEval( NULL,                'select cast(''a'' as varchar2(14)) "Ans" from dual',                'HelloWorld'));BEGIN--     sys.rqScriptDrop('Example1');     sys.rqScriptCreate('Example1',        'function() {           ID <- sample(seq(100), 11)           res <- data.frame(ID = ID)           res } '); END; /  SELECT * FROM   table( rqEval(NULL,                  'select 1 id from dual',                  'Example1')); BEGIN--     sys.rqScriptDrop('Example2');     sys.rqScriptCreate('Example2',        'function(NumPoints, SampleSize) {           ID <- sample(seq(NumPoints), SampleSize)           res <- data.frame(ID = ID)           res } '); END; /  SELECT * FROM   table( rqEval(cursor(select 50 "NumPoints", 6 "SampleSize" from dual),                  'select 1 id from dual',                  'Example2')); BEGIN--   sys.rqScriptDrop('plyrExample');   sys.rqScriptCreate('plyrExample',        'function(dat) {           library(plyr)           df3 <- dat           res <- ddply(df3, .(CUST_GENDER), summarize, freq=length(CUST_ID))           res } ');END;SELECT *FROM   table( rqTableEval( cursor(select * from customers_v),         NULL,         'select cast(''a'' as varchar2(14)) "Cust_Gender", 1 as freq from dual',         'plyrExample'));-- Build & save the R script, called Demo_GLM in the DB--  This builds a GLM  DM model in the DB--BEGIN--   sys.rqScriptDrop('Demo_GLM');   sys.rqScriptCreate('Demo_GLM',      'function(dat,datastore_name) {          mod <- glm(AFFINITY_CARD ~ CUST_GENDER + AGE + CUST_MARITAL_STATUS + COUNTRY_NAME + CUST_INCOME_LEVEL + EDUCATION + HOUSEHOLD_SIZE + YRS_RESIDENCE, dat, family = binomial())       ore.save(mod, name=datastore_name, overwrite=TRUE)   }');END;---- After creating the script you need to run it to create the GLM model--SELECT * 	FROM table(rqTableEval(             cursor(select CUST_GENDER,                           AGE,                           CUST_MARITAL_STATUS,                           COUNTRY_NAME,                           CUST_INCOME_LEVEL,                           EDUCATION,                           HOUSEHOLD_SIZE,                           YRS_RESIDENCE,                           AFFINITY_CARD                    from mining_data_build_v),             cursor(select 1 as "ore.connect", 'myDatastore' as "datastore_name" from dual)                  'XML', 'Demo_GLM' ));
-- Script to apply the GLM data mining model to your new dataBEGIN--   sys.rqScriptDrop('Demo_GLM_Batch');   sys.rqScriptCreate('Demo_GLM_Batch',      'function(dat, datastore_name) {      ore.load(datastore_name)      prd <- predict(mod, newdata=dat)      prd[as.integer(rownames(prd))] <- prd      res <- cbind(dat, PRED = prd)      res}');END;/SELECT * FROM table(rqTableEval(     cursor(select CUST_GENDER, AGE, CUST_MARITAL_STATUS, COUNTRY_NAME,                   CUST_INCOME_LEVEL, EDUCATION, HOUSEHOLD_SIZE, YRS_RESIDENCE                     from   MINING_DATA_APPLY_V                     where rownum <= 10),     cursor(select 1 as "ore.connect", 'myDatastore' as "datastore_name"             from dual),     'select CUST_GENDER, AGE, CUST_MARITAL_STATUS, COUNTRY_NAME,             CUST_INCOME_LEVEL, EDUCATION, HOUSEHOLD_SIZE, YRS_RESIDENCE,              1 PRED from MINING_DATA_APPLY_V','Demo_GLM_Batch'))ORDER BY 1, 2, 3;BEGIN--   sys.rqScriptDrop('AgeProfile');   sys.rqScriptCreate('AgeProfile',      'function(dat) {         mdbv <- dat         aggdata <- aggregate(mdbv$AFFINITY_CARD,                              by = list(Age = mdbv$AGE),                              FUN = length)         res <- plot(aggdata$Age, aggdata$x, type = "l") } ');END;/SELECT * FROM table(rqTableEval(          cursor(select * from ANALYTIC_RECORD),                                      cursor(select 1 "ore.connect" from dual),                                      'PNG', 'AgeProfile'));